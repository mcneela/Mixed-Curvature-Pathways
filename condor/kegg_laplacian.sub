universe = vanilla
requirements = (OpSysMajorVer == 7) || (OpSysMajorVer == 8)

# the script that will be run when the job starts
executable = condor/kegg_laplacian.sh

# include the cluster id and process id that are set at runtime
log = output/condor_logs/job_$(Cluster)_$(Process).log
error = output/condor_logs/job_$(Cluster)_$(Process).err
output = output/condor_logs/job_$(Cluster)_$(Process).out

# these files get transferred from the submit node to the server on which the program is executing
# transfer over code, data, and arguments
transfer_input_files = code/multiset/graph_laplacian_embed.py, kegg_data.tar.gz, env.tar.gz
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_output_files = output, kegg_laplacian_models/
preserve_relative_paths = true

request_gpus = 1
request_cpus = 2
request_memory = 16GB
request_disk = 20GB

accounting_group = BMI_Gitter
+WantGPULab = true
+GPUJobLength = "short"
+WantFlocking = true

# these environment variables will be set on the execute node
# useful for printing info and setting GitHub, WandB keys
environment = "CLUSTER=$(Cluster) PROCESS=$(Process) RUNNINGON=$$(Name) GITHUB_TAG=$ENV(GITHUB_TAG) WANDB_API_KEY=$ENV(WANDB_API_KEY)"

queue 1
