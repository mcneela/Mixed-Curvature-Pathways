universe = vanilla
requirements = (OpSysMajorVer == 7) || (OpSysMajorVer == 8)

# the script that will be run when the job starts
executable = condor/kegg_best_embeddings.sh

# include the cluster id and process id that are set at runtime
log = output/condor_logs/job_$(Cluster)_$(Process).log
error = output/condor_logs/job_$(Cluster)_$(Process).err
output = output/condor_logs/job_$(Cluster)_$(Process).out

# these files get transferred from the submit node to the server on which the program is executing
# transfer over code, data, and arguments
transfer_input_files = kegg/kegg_unique_best_spaces.tsv, processing/generate_best_embeddings.py, run.sh, kegg_data.tar.gz, code.tar.gz, env.tar.gz
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_output_files = output, kegg_models
preserve_relative_paths = true

request_cpus = 2
request_memory = 8GB
request_disk = 10GB

+WantFlocking = true

# these environment variables will be set on the execute node
# useful for printing info and setting GitHub, WandB keys
environment = "CLUSTER=$(Cluster) PROCESS=$(Process) RUNNINGON=$$(Name) GITHUB_TAG=$ENV(GITHUB_TAG) WANDB_API_KEY=$ENV(WANDB_API_KEY)"

queue 1
