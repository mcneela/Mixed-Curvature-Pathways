universe = vanilla
requirements = (OpSysMajorVer == 7) || (OpSysMajorVer == 8)

# the script that will be run when the job starts
executable = run_n2v.sh

# include the cluster id and process id that are set at runtime
log = output/condor_logs/job_$(Cluster)_$(Process).log
error = output/condor_logs/job_$(Cluster)_$(Process).err
output = output/condor_logs/job_$(Cluster)_$(Process).out

# these files get transferred from the submit node to the server on which the program is executing
# transfer over code, data, and arguments
transfer_input_files = run_node2vec.py, run_n2v.sh, pathbank_data.tar.gz, odd.tar.gz, node2vec
should_transfer_files = YES
when_to_transfer_output = ON_EXIT
transfer_output_files = output, node2vec/
preserve_relative_paths = true

request_gpus = 1
request_cpus = 2
request_memory = 16GB
request_disk = 20GB

accounting_group = BMI_Gitter
+WantGPULab = true
+GPUJobLength = "short"
+WantFlocking = true

# these environment variables will be set on the execute node
# useful for printing info and setting GitHub, WandB keys
environment = "CLUSTER=$(Cluster) PROCESS=$(Process) RUNNINGON=$$(Name) GITHUB_TAG=$ENV(GITHUB_TAG) WANDB_API_KEY=$ENV(WANDB_API_KEY)"

queue 1
